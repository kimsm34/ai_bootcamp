{"cells":[{"cell_type":"markdown","metadata":{"id":"QPnOdOwb-SUh"},"source":["model"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11263,"status":"ok","timestamp":1660915037035,"user":{"displayName":"kyumin kim","userId":"10396232010977041407"},"user_tz":-540},"id":"hFObPWNAeIao","outputId":"5a21e9c4-c2b8-4619-a928-979e8377a317"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting transformers==3.0.2\n","  Downloading transformers-3.0.2-py3-none-any.whl (769 kB)\n","\u001b[K     |████████████████████████████████| 769 kB 8.8 MB/s \n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.2) (4.64.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.2) (2022.6.2)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.2) (21.3)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.2) (1.21.6)\n","Collecting sentencepiece!=0.1.92\n","  Downloading sentencepiece-0.1.97-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[K     |████████████████████████████████| 1.3 MB 36.4 MB/s \n","\u001b[?25hCollecting tokenizers==0.8.1.rc1\n","  Downloading tokenizers-0.8.1rc1-cp37-cp37m-manylinux1_x86_64.whl (3.0 MB)\n","\u001b[K     |████████████████████████████████| 3.0 MB 40.4 MB/s \n","\u001b[?25hCollecting sacremoses\n","  Downloading sacremoses-0.0.53.tar.gz (880 kB)\n","\u001b[K     |████████████████████████████████| 880 kB 42.1 MB/s \n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.2) (3.8.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.2) (2.23.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers==3.0.2) (3.0.9)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.0.2) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.0.2) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.0.2) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.0.2) (2022.6.15)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3.0.2) (1.15.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3.0.2) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3.0.2) (1.1.0)\n","Building wheels for collected packages: sacremoses\n","  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895260 sha256=b58a4dd4241f7f77b86cb90a315d30e93671ef215839f5f17a31d30d1803aab3\n","  Stored in directory: /root/.cache/pip/wheels/87/39/dd/a83eeef36d0bf98e7a4d1933a4ad2d660295a40613079bafc9\n","Successfully built sacremoses\n","Installing collected packages: tokenizers, sentencepiece, sacremoses, transformers\n","Successfully installed sacremoses-0.0.53 sentencepiece-0.1.97 tokenizers-0.8.1rc1 transformers-3.0.2\n"]}],"source":["!pip install transformers==3.0.2"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1660915037035,"user":{"displayName":"kyumin kim","userId":"10396232010977041407"},"user_tz":-540},"id":"pDmsaQJ0rnyg"},"outputs":[],"source":["def mount_drive():  \n","    from google.colab import drive\n","    drive.mount('/content/gdrive')"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":19635,"status":"ok","timestamp":1660915056667,"user":{"displayName":"kyumin kim","userId":"10396232010977041407"},"user_tz":-540},"id":"sMTTH0AAiV9O","outputId":"3a0cfb00-fc9f-4708-af17-32600dc5be33"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n"]}],"source":["if __name__ == \"__main__\":\n","    mount_drive()"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":5767,"status":"ok","timestamp":1660915062432,"user":{"displayName":"kyumin kim","userId":"10396232010977041407"},"user_tz":-540},"id":"9Tj07ECUMfN-"},"outputs":[],"source":["import torch\n","from transformers import get_linear_schedule_with_warmup, BertForSequenceClassification, BertConfig\n","import numpy as np"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1660915062432,"user":{"displayName":"kyumin kim","userId":"10396232010977041407"},"user_tz":-540},"id":"07CmMoztqKZJ"},"outputs":[],"source":["from torch import nn\n","from transformers import BertModel, BertConfig\n","\n","class BertClassifier(nn.Module):\n","\n","    # BertClassifier는 초대용량 AI 모델인 BertModel을 파인튜닝한 모델이다.\n","    # 구체적으로, BertModel 위에 linear한 층 하나를 추가해 놓은 모델이다.\n","    # Bert -> Linear -> Softmax의 순서로 연산이 이루어진다.\n","    # 우리가 Loss를 구하는데 사용되는 CrossEntropyLoss의 경우, softmax를 자동으로 포함하여 연산해준다.\n","    # 고로, BertClassifier 클래스 내의 forward 함수에, softmax는 포함시키지 않는다.\n","    # 단, 학습의 용도가 아니라 테스트나 실제 시연을 할 때는 forward 결과물에 softmax를 적용시켜줘야 한다.\n","\n","    def __init__(self, num_labels=7, dr_rate=None, params = None):\n","\n","        super(BertClassifier, self).__init__()\n","\n","        model_config = BertConfig.from_pretrained('monologg/kobert')\n","        \n","        # model_config와 from_pretrained 함수를 활용해서 bert 모델을 선언해주자.\n","        # self.bert = ~~ 꼴로 작성해주자.\n","        ## 여기에 코드 작성\n","        self.bert = BertModel.from_pretrained('monologg/kobert', config = model_config)\n","\n","        # nn 라이브러리를 활용해서 linear 모델을 선언해주자.\n","        # self.linear = ~~ 꼴로 작성해주자.\n","        # bert의 경우, 768차원 벡터를 산출해준다.\n","        # linear는 768차원의 값을 입력받아 7차원의 값을 출력해주어야 한다.\n","        ## 여기에 코드 작성\n","        self.linear = nn.Linear( 768, out_features = num_labels)\n","\n","        ##drop out 여기 코드 작성 내가 추가함\n","        self.dr_rate=dr_rate\n","        if dr_rate:\n","          self.dropout = nn.Dropout(p=dr_rate)\n","\n","    def forward(self, input_ids, attention_mask):\n","        # 위에서 생성한 self.bert, self.linear 두 개의 layer를 활용하면 된다.\n","        # bert -> linear를 적용해준 다음, 출력값을 리턴해주자.\n","        # Hint: 만약 __init__에서 self.bert라는 bert layer를 생성하였고 이를 forward 함수에서 활용하려면, 생성한 bert layer의 forward 함수를 활용하면 될 것이다.\n","        #       bert layer의 forward 함수는 input_ids와 attention_mask를 변수로 입력받아야 한다. 이에 따라, self.bert(input_ids, attention_mask)와 같은 방식으로 코드를 작성하면 될 것이다.\n","        \n","        ## 여기에 코드 작성\n","        #out=self.bert(input_ids, attention_mask)\n","        \n","        #out = torch.Tensor(out[-1])  #only one element tensors can be converted to Python scalars 에러 생성 없으면 linear에 tuple 이 들어간다고 에러\n","        #print(np.shape(out))\n","        #out = torch.Tensor(out)\n","        _, out = self.bert(input_ids, attention_mask)\n","        if self.dr_rate:\n","          out = self.dropout(out)\n","        \n","\n","        out=self.linear(out)\n","\n","        return out \n","\n","        #pass"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1660915062432,"user":{"displayName":"kyumin kim","userId":"10396232010977041407"},"user_tz":-540},"id":"GXFoQEm9-NUJ"},"outputs":[],"source":["# 분류를 위한 BERT 모델 생성\n","# BertModel을 초기화하는 역할\n","def BertModelInitialization():\n","    PATH = \"/content/gdrive/MyDrive/NLP/model_5.pt\"\n","    \n","    # BertModel은 다양한 작업을 진행할 수 있도록 해주는 여러 인터페이스들을 제공한다.\n","    # 그 중, 본 중간 미션의 task에 가장 적합한 인터페이스를 찾아보자.\n","    # Hint 1 : HuggingFace 홈페이지에 Bert를 검색해서 찾아보자.\n","    # URL : https://huggingface.co/docs/transformers/main/en/index\n","    # Hint 2 : 본 중간 미션이, 영화리뷰를 긍정과 부정의 두 가지 감정으로 분류해내는 작업임을 고려해보자.\n","\n","    model = BertClassifier(dr_rate = 0.25)\n","    #model = BertForSequenceClassification.from_pretrained('monologg/kobert', num_labels=7)\n","\n","    # 생성한 모델을 특정 PATH에 저장\n","    torch.save(model.state_dict(), PATH)"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1660915062433,"user":{"displayName":"kyumin kim","userId":"10396232010977041407"},"user_tz":-540},"id":"q8oypFVGdt2X"},"outputs":[],"source":["def get_model(device, cuda_available):\n","    PATH = \"model_5.pt\"\n","\n","    model = BertClassifier()\n","\n","\n","    if cuda_available:\n","        # PATH에 저장된 모델 불러옴\n","        model.load_state_dict(torch.load(PATH), strict=False)\n","\n","        # 불러온 모델을 device에 등록\n","        model = model.to(device)\n","    else:\n","        # PATH에 저장된 모델을 불러오기 및 불러온 모델을 device에 등록\n","        model.load_state_dict(torch.load(PATH, map_location=device), strict=False)\n","    \n","    return model"]},{"cell_type":"markdown","metadata":{"id":"fUf6MZ3zplat"},"source":["**신경망 성능 향상을 위한 다양한 툴**\n","\n","\n","\n","> 최종미션을 위한 이론문서를 확인해보자.\n","\n","\n","- 여러분은 옵티마이저, 에포크 수, 스케줄러 종류를 본 task에 가장 적합한 것으로 선택하여 바꿀 수 있다.\n","- 정답은 없다. 최적의 모델을 선택하여 신경망의 성능을 높여보자!\n","\n","\n"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1660915062433,"user":{"displayName":"kyumin kim","userId":"10396232010977041407"},"user_tz":-540},"id":"BcFCBaNkXxrv"},"outputs":[],"source":["def get_model_with_params(num_data, device, cuda_available):\n","    model = get_model(device, cuda_available)\n","\n","    no_decay = ['bias', 'LayerNorm.weight']\n","    optimizer_grouped_parameters = [\n","    {'params': [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n","    {'params': [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n","    ]\n","\n","    # 옵티마이저 설정\n","    optimizer = torch.optim.AdamW(#model.parameters(),\n","                                  optimizer_grouped_parameters,\n","                      lr = 1e-5, # 학습률\n","                      eps = 1e-8 # 0으로 나누는 것을 방지하기 위한 epsilon 값,\n","                    )\n","    # 전체 데이터가 총 몇 번 학습되는지\n","    epochs = 10\n","\n","    # 총 훈련 스텝\n","    total_steps = num_data * epochs\n","    warmup_step = int(total_steps * 0.1)\n","\n","    # 학습이 이루어짐에 따라 learning_rate을 감소시키기 위한 스케줄러\n","    scheduler = get_linear_schedule_with_warmup(optimizer, \n","                                                num_warmup_steps = warmup_step,\n","                                                num_training_steps = total_steps)\n","  \n","    # nn 라이브러리에서 crossentropy 형식으로 loss를 계산하는 모델을 찾아서 손실함수로 설정해주자.\n","    # criterion = ~~ 꼴로 작성해주자.\n","    ## 여기에 코드 작성\n","    criterion = nn.CrossEntropyLoss()\n","    \n","    return model, optimizer, scheduler, epochs, criterion\n"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1660915062433,"user":{"displayName":"kyumin kim","userId":"10396232010977041407"},"user_tz":-540},"id":"ihB4OGzxscad"},"outputs":[],"source":["def main():\n","    %cd /content/gdrive/MyDrive/NLP\n","    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","    BertModelInitialization()\n","    print(get_model_with_params(34388, device, True))"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["11073be1259542b0947ddaa6e8b657b7","cafd3ad9c3de45fdabb80b8ca9a90cca","258b44b3c40b4751b7fbec5f33e6b6c0","00070d4a2659465d80c4bc46350f5f22","09f6a1d65f7e4ebfb20d15b4d1abdb9b","6d2c24efe03348b8826232d8d902e571","e3490c441f214cc98fd9145c203885c8","5c65ade51e3e4bbc9f06b207bacaff70","e171c176370341dfa085e538b80da458","baf463bbfe2047dfb5d37a388085e283","95bec289c18c40aa9e889f3f90779273","a0f3a94819d341c19a9c9040820cc0e1","ddb84aa83d3f4039939451fb9f41ea1a","301b12d43347440a8bc17854be0182be","9208d1c93f124b0f9f2328ad49e52a47","4dffafe4457c49058b4561c84212f2e3","1d3daec5545d49a7972f9d177ac83989","b62370331c2e46e193ccc59162c0a5c9","2fdf9cd8dfc149d3af5d67540d226315","8172fca0190d4d2e8c595af8ef40dcd1","7a89dd6ccec642e2bb05623eba039185","9c57c5865e1a4f5eac9291757380cdfc"]},"executionInfo":{"elapsed":19519,"status":"ok","timestamp":1660915081948,"user":{"displayName":"kyumin kim","userId":"10396232010977041407"},"user_tz":-540},"id":"KvhcU7f8Vdxy","outputId":"7b283e85-f7a6-4d8d-ba57-c465389e2664"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/gdrive/MyDrive/NLP\n"]},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/426 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"11073be1259542b0947ddaa6e8b657b7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/369M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a0f3a94819d341c19a9c9040820cc0e1"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["(BertClassifier(\n","  (bert): BertModel(\n","    (embeddings): BertEmbeddings(\n","      (word_embeddings): Embedding(8002, 768, padding_idx=1)\n","      (position_embeddings): Embedding(512, 768)\n","      (token_type_embeddings): Embedding(2, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): BertEncoder(\n","      (layer): ModuleList(\n","        (0): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (1): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (2): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (3): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (4): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (5): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (6): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (7): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (8): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (9): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (10): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (11): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (pooler): BertPooler(\n","      (dense): Linear(in_features=768, out_features=768, bias=True)\n","      (activation): Tanh()\n","    )\n","  )\n","  (linear): Linear(in_features=768, out_features=7, bias=True)\n","), AdamW (\n","Parameter Group 0\n","    amsgrad: False\n","    betas: (0.9, 0.999)\n","    capturable: False\n","    eps: 1e-08\n","    foreach: None\n","    initial_lr: 1e-05\n","    lr: 0.0\n","    maximize: False\n","    weight_decay: 0.01\n","\n","Parameter Group 1\n","    amsgrad: False\n","    betas: (0.9, 0.999)\n","    capturable: False\n","    eps: 1e-08\n","    foreach: None\n","    initial_lr: 1e-05\n","    lr: 0.0\n","    maximize: False\n","    weight_decay: 0.0\n","), <torch.optim.lr_scheduler.LambdaLR object at 0x7f4451d28dd0>, 10, CrossEntropyLoss())\n"]}],"source":["if __name__ == '__main__':\n","      main()"]}],"metadata":{"colab":{"collapsed_sections":[],"name":"nlp_model_final.ipynb","provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.13"},"widgets":{"application/vnd.jupyter.widget-state+json":{"11073be1259542b0947ddaa6e8b657b7":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_cafd3ad9c3de45fdabb80b8ca9a90cca","IPY_MODEL_258b44b3c40b4751b7fbec5f33e6b6c0","IPY_MODEL_00070d4a2659465d80c4bc46350f5f22"],"layout":"IPY_MODEL_09f6a1d65f7e4ebfb20d15b4d1abdb9b"}},"cafd3ad9c3de45fdabb80b8ca9a90cca":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6d2c24efe03348b8826232d8d902e571","placeholder":"​","style":"IPY_MODEL_e3490c441f214cc98fd9145c203885c8","value":"Downloading: 100%"}},"258b44b3c40b4751b7fbec5f33e6b6c0":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_5c65ade51e3e4bbc9f06b207bacaff70","max":426,"min":0,"orientation":"horizontal","style":"IPY_MODEL_e171c176370341dfa085e538b80da458","value":426}},"00070d4a2659465d80c4bc46350f5f22":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_baf463bbfe2047dfb5d37a388085e283","placeholder":"​","style":"IPY_MODEL_95bec289c18c40aa9e889f3f90779273","value":" 426/426 [00:00&lt;00:00, 4.76kB/s]"}},"09f6a1d65f7e4ebfb20d15b4d1abdb9b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6d2c24efe03348b8826232d8d902e571":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e3490c441f214cc98fd9145c203885c8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5c65ade51e3e4bbc9f06b207bacaff70":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e171c176370341dfa085e538b80da458":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"baf463bbfe2047dfb5d37a388085e283":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"95bec289c18c40aa9e889f3f90779273":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a0f3a94819d341c19a9c9040820cc0e1":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_ddb84aa83d3f4039939451fb9f41ea1a","IPY_MODEL_301b12d43347440a8bc17854be0182be","IPY_MODEL_9208d1c93f124b0f9f2328ad49e52a47"],"layout":"IPY_MODEL_4dffafe4457c49058b4561c84212f2e3"}},"ddb84aa83d3f4039939451fb9f41ea1a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1d3daec5545d49a7972f9d177ac83989","placeholder":"​","style":"IPY_MODEL_b62370331c2e46e193ccc59162c0a5c9","value":"Downloading: 100%"}},"301b12d43347440a8bc17854be0182be":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_2fdf9cd8dfc149d3af5d67540d226315","max":368792146,"min":0,"orientation":"horizontal","style":"IPY_MODEL_8172fca0190d4d2e8c595af8ef40dcd1","value":368792146}},"9208d1c93f124b0f9f2328ad49e52a47":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7a89dd6ccec642e2bb05623eba039185","placeholder":"​","style":"IPY_MODEL_9c57c5865e1a4f5eac9291757380cdfc","value":" 369M/369M [00:09&lt;00:00, 52.0MB/s]"}},"4dffafe4457c49058b4561c84212f2e3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1d3daec5545d49a7972f9d177ac83989":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b62370331c2e46e193ccc59162c0a5c9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2fdf9cd8dfc149d3af5d67540d226315":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8172fca0190d4d2e8c595af8ef40dcd1":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"7a89dd6ccec642e2bb05623eba039185":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9c57c5865e1a4f5eac9291757380cdfc":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}